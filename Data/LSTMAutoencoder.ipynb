{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitmtgenvvenvef0a1ddebe9b47dda592fd70f6ed8719",
   "display_name": "Python 3.7.4 64-bit ('MTGENV': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stupid jupyter path is in the venv directory, so this is in MTG-INVESTOR-S-GRAIL\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.utils import Sequence\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import sadness as sadness\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making file with text from all cards\n",
    "dftemp1 = pd.read_csv('LSTMData.csv', sep=',')\n",
    "dftemp1 = dftemp1[pd.notnull(dftemp1['text'])]\n",
    "with open('LSTMData.txt', 'w', encoding='UTF-8') as fileboi:\n",
    "    for tupleboi in dftemp1.itertuples():\n",
    "        if str(tupleboi[1]).count('nan') == 0:\n",
    "            fileboi.write(str(tupleboi[1])+ '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2jank = 'LSTMData.txt'\n",
    "mask_value = -1\n",
    "janktext = open(path2jank, 'rb').read().decode(encoding='utf-8')\n",
    "vocablist = sorted(set(janktext).union(set(sadness.safe_string)))\n",
    "num_chars = len(vocablist) + 1\n",
    "char2idx = {u:i for i, u in enumerate(vocablist)}\n",
    "char2idx[str(mask_value)] = num_chars\n",
    "idx2char = {value:key for key, value in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "100 unique characters\n{'\\n': 0, '\\r': 0, ' ': 0, '!': 0, '\"': 0, '&': 0, \"'\": 0, '(': 0, ')': 0, '+': 0, ',': 0, '-': 0, '.': 0, '/': 0, '0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, ':': 0, ';': 0, '?': 0, 'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0, 'G': 0, 'H': 0, 'I': 0, 'J': 0, 'K': 0, 'L': 0, 'M': 0, 'N': 0, 'O': 0, 'P': 0, 'Q': 0, 'R': 0, 'S': 0, 'T': 0, 'U': 0, 'V': 0, 'W': 0, 'X': 0, 'Y': 0, 'Z': 0, '[': 0, ']': 0, '_': 0, 'a': 0, 'b': 0, 'c': 0, 'd': 0, 'e': 0, 'f': 0, 'g': 0, 'h': 0, 'i': 0, 'j': 0, 'k': 0, 'l': 0, 'm': 0, 'n': 0, 'o': 0, 'p': 0, 'q': 0, 'r': 0, 's': 0, 't': 0, 'u': 0, 'v': 0, 'w': 0, 'x': 0, 'y': 0, 'z': 0, '{': 0, '}': 0, '®': 0, '½': 0, 'á': 0, 'â': 0, 'é': 0, 'í': 0, 'ö': 0, 'ú': 0, 'û': 0, 'π': 0, '—': 0, '•': 0, '−': 0, '∞': 0, '☐': 0, '-1': 0}\n"
    }
   ],
   "source": [
    "print ('{} unique characters'.format(num_chars))\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_char(string):\n",
    "    return [char2idx[char] for char in str(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(47396, 770, 1) (47396, 770, 100)\n"
    }
   ],
   "source": [
    "\n",
    "max_time_steps = shuffle(dftemp1).text.map(len).max()\n",
    "x_train = np.full(shape=(len(dftemp1[\"text\"]), max_time_steps, 1), fill_value=char2idx[str(mask_value)])\n",
    "y_train = x_train\n",
    "#y_train = np.zeros((len(dftemp1[\"oracle_text\"]), max_time_steps, 1))\n",
    "for s, x in enumerate(dftemp1.text.map(convert_char).to_numpy()):\n",
    "    seq_len = len(x)\n",
    "    x_train[s, 0:seq_len, :] = np.reshape(x, (seq_len, 1))\n",
    "    y_train[s, 0:seq_len, :] = np.reshape(x, (seq_len, 1))\n",
    "y_train = tf.keras.utils.to_categorical(y_train-1, num_classes=num_chars)\n",
    "#x_train = np.reshape(x_train, (x_train.shape[0], max_time_steps))\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training: (28437, 770, 1), Cross val: (9479, 770, 1), Testing: (9480, 770, 1)\ny_vals Training: (28437, 770, 100), Cross val: (9479, 770, 100), Testing: (9480, 770, 100)\n"
    }
   ],
   "source": [
    "set_length = x_train.shape[0]\n",
    "cv_idx = int(set_length * .6)\n",
    "test_idx = int(set_length * .8)\n",
    "\n",
    "\n",
    "x_cv = x_train[cv_idx:test_idx, :]\n",
    "y_cv = y_train[cv_idx:test_idx, :]\n",
    "\n",
    "x_test = x_train[test_idx:, :]\n",
    "y_test = y_train[test_idx:, :]\n",
    "\n",
    "x_train = x_train[:cv_idx, :]\n",
    "y_train = y_train[:cv_idx, :]\n",
    "\n",
    "print(\"Training: {}, Cross val: {}, Testing: {}\".format(x_train.shape, x_cv.shape, x_test.shape))\n",
    "print(\"y_vals Training: {}, Cross val: {}, Testing: {}\".format(y_train.shape, y_cv.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
<<<<<<< HEAD
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 770, 1)]          0         \n_________________________________________________________________\nreshape (Reshape)            (None, 770)               0         \n_________________________________________________________________\nembedding (Embedding)        (None, 770, 256)          25856     \n_________________________________________________________________\nlstm (LSTM)                  (None, 500)               1514000   \n_________________________________________________________________\nrepeat_vector (RepeatVector) (None, 770, 500)          0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 770, 100)          240400    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 770, 500)          1202000   \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 770, 100)          50100     \n=================================================================\nTotal params: 3,032,356\nTrainable params: 3,032,356\nNon-trainable params: 0\n_________________________________________________________________\n"
=======
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 769, 1)]          0         \n_________________________________________________________________\nreshape (Reshape)            (None, 769)               0         \n_________________________________________________________________\nembedding (Embedding)        (None, 769, 256)          25856     \n_________________________________________________________________\nlstm (LSTM)                  (None, 1000)              5028000   \n_________________________________________________________________\nrepeat_vector (RepeatVector) (None, 769, 1000)         0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 769, 2000)         24008000  \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 769, 100)          200100    \n=================================================================\nTotal params: 29,261,956\nTrainable params: 29,261,956\nNon-trainable params: 0\n_________________________________________________________________\n"
>>>>>>> 4984ef99b211ada0706bb52962692d000f8c962d
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "\n",
    "visible = tf.keras.layers.Input(shape=(max_time_steps, 1))\n",
    "encoder = tf.keras.layers.Reshape((max_time_steps,))(visible)\n",
    "encoder = tf.keras.layers.Embedding(num_chars+1, embedding_dim)(encoder)\n",
    "encoder = tf.keras.layers.LSTM(1000)(encoder)\n",
    "decoder = tf.keras.layers.RepeatVector(max_time_steps)(encoder)\n",
    "decoder = tf.keras.layers.LSTM(2000, return_sequences = True)(decoder)\n",
    "decoder = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_chars))(decoder)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(inputs=visible, outputs=decoder)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = tf.keras.layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"Data/LSTMCheckpoints/LSTM_AEnc1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-876ec9a1021b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/LSTMCheckpoints/LSTM_AEnc2.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=50)\n",
    "model.save(\"Data/LSTMCheckpoints/LSTM_AEnc2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Data/LSTMCheckpoints/LSTM_AEnc2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\".join([idx2char[int(char[0])] if char[0] > 0 else \"\" for char in x_train[0:1][0].tolist()]))\n",
    "print([idx2char[int(char[0])] if int(char[0]) > 0 else \"\" for char in (model.predict(x_train[0:1].astype(np.float32)).tolist()[0])])\n",
    "print(\"\".join([idx2char[int(char[0])] if int(char[0]) > 0 else \"\" for char in (model.predict(x_train[0:1].astype(np.float32)).tolist()[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}